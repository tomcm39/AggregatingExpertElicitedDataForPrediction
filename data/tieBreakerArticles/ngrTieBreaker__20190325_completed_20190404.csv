,TI,AB,DI,PY,crowd,experts,aggregation,all,notes
1,Toward a ground-motion logic tree for probabilistic seismic hazard assessment in Europe,"The Seismic Hazard Harmonization in Europe (SHARE) project, which began in June 2009, aims at establishing new standards for probabilistic seismic hazard assessment in the Euro-Mediterranean region. In this context, a logic tree for ground-motion prediction in Europe has been constructed. Ground-motion prediction equations (GMPEs) and weights have been determined so that the logic tree captures epistemic uncertainty in ground-motion prediction for six different tectonic regimes in Europe. Here we present the strategy that we adopted to build such a logic tree. This strategy has the particularity of combining two complementary and independent approaches: expert judgment and data testing. A set of six experts was asked to weight pre-selected GMPEs while the ability of these GMPEs to predict available data was evaluated with the method of Scherbaum et al. (Bull Seismol Soc Am 99:3234-3247, 2009). Results of both approaches were taken into account to commonly select the smallest set of GMPEs to capture the uncertainty in ground-motion prediction in Europe. For stable continental regions, two models, both from eastern North America, have been selected for shields, and three GMPEs from active shallow crustal regions have been added for continental crust. For subduction zones, four models, all non-European, have been chosen. Finally, for active shallow crustal regions, we selected four models, each of them from a different host region but only two of them were kept for long periods. In most cases, a common agreement has been also reached for the weights. In case of divergence, a sensitivity analysis of the weights on the seismic hazard has been conducted, showing that once the GMPEs have been selected, the associated set of weights has a smaller influence on the hazard.",10.1007/s10950-012-9281-z,2012,Y,Y,N,FALSE,
2,A Bayesian Network Modeling Approach to Forecasting the 21st Century Worldwide Status of Polar Bears,"To inform the U.S. Fish and Wildlife Service decision, whether or not to list polar bears as threatened under the Endangered Species Act (ESA), we projected the status of the world's polar bears (Ursus maritimus) for decades centered on future years 2025, 2050, 2075, and 2095. We defined four ecoregions based on current and projected sea ice conditions: seasonal ice, Canadian Archipelago, polar basin divergent, and polar basin convergent ecoregions. We incorporated general circulation model projections of future sea ice into a Bayesian network (BN) model structured around the factors considered in ESA decisions. This first-generation BN model combined empirical data, interpretations of data, and professional judgments of one polar bear expert into a probabilistic framework that identifies causal links between environmental stressors and polar bear responses. We provide guidance regarding steps necessary to refine the model, including adding inputs from other experts. The BN model projected extirpation of polar bears from the seasonal ice and polar basin divergent ecoregions, where approximate to 2/3 of the world's polar bears currently occur, by mid century. Projections were less dire in other ecoregions. Decline in ice habitat was the overriding factor driving the model outcomes. Although this is a first-generation model, the dependence of polar bears on sea ice is universally accepted, and the observed sea ice decline is faster than models suggest. Therefore, incorporating judgments of multiple experts in a final model is not expected to fundamentally alter the outlook for polar bears described here.",10.1029/180GM14,2008,N,Y,N,FALSE,
3,The limits of forecasting methods in anticipating rare events,"In this paper we review methods that aim to aid the anticipation of rare, high-impact, events. We evaluate these methods according to their ability to yield well-calibrated probabilities or point forecasts for such events. We first identify six factors that can lead to poor calibration and then examine how successful the methods are in mitigating these factors. We demonstrate that all the extant forecasting methods including the use of expert judgment, statistical forecasting. Delphi and prediction markets contain fundamental weaknesses. We contrast these methods with a non-forecasting method that is intended to aid planning for the future scenario planning. We conclude that all the methods are problematic for aiding the anticipation of rare events and that the only remedies are to either (i) to provide protection for the organization against the occurrence of negatively-valenced events whilst allowing the organization to benefit from the occurrence of positively-valenced events, or (ii) to provide conditions to challenge one's own thinking and hence improve anticipation. We outline how components of devil's advocacy and dialectical inquiry can be combined with Delphi and scenario planning to enhance anticipation of rare events. (C) 2009 Elsevier Inc. All rights reserved.",10.1016/j.techfore.2009.10.008,2010,N,Y,N,FALSE,
4,The relative importance of the face and body in judgments of human physical attractiveness,"A number of traits have been proposed to be important in human mate choice decisions. However, relatively little work has been conducted to determine the relative importance of these traits. In this study, we assessed the relative importance of the face and body in judgments of human physical attractiveness. One hundred twenty-seven men and 133 women were shown images of 10 individuals of the opposite sex. Participants rated the images for their attractiveness for either a short-term relationship or a long-term relationship. Images of the face and the body were rated independently before participants were shown and asked to rate the combined face and body images. Face ratings were found to be the best predictor of the ratings of combined images for both sexes and for both relationship types. Females showed no difference in ratings between short- and long-term conditions, but male ratings of female bodies became relatively more important for a short-term relationship compared with a long-term relationship. Results suggest that faces and bodies may be signaling different information about potential mates. (C) 2009 Elsevier Inc. All rights reserved.",10.1016/j.evolhumbehav.2009.06.005,2009,Y,N,Y,FALSE,
6,Differential Diagnosis of Children with Suspected Childhood Apraxia of Speech,"Purpose: The gold standard for diagnosing childhood apraxia of speech (CAS) is expert judgment of perceptual features. The aim of this study was to identify a set of objective measures that differentiate CAS from other speech disorders. Method: Seventy-two children (4-12 years of age) diagnosed with suspected CAS by community speech-language pathologists were screened. Forty-seven participants underwent diagnostic assessment including presence or absence of perceptual CAS features. Twenty-eight children met two sets of diagnostic criteria for CAS (American Speech-Language-Hearing Association, 2007b; Shriberg, Potter, & Strand, 2009); another 4 met the CAS criteria with comorbidity. Fifteen were categorized as non-CAS with phonological impairment, submucous cleft, or dysarthria. Following this, 24 different measures from the diagnostic assessment were rated by blinded raters. Multivariate discriminant function analysis was used to identify the combination of measures that best predicted expert diagnoses. Results: The discriminant function analysis model, including syllable segregation, lexical stress matches, percentage phonemes correct from a polysyllabic picture-naming task, and articulatory accuracy on repetition of /peteke/, reached 91% diagnostic accuracy against expert diagnosis. Conclusions: Polysyllabic production accuracy and an oral motor examination that includes diadochokinesis may be sufficient to reliably identify CAS and rule out structural abnormality or dysarthria. Testing with a larger unselected sample is required.",10.1044/2014_JSLHR-S-12-0358,2015,N,Y,N,FALSE,
7,Improving predictive accuracy with a combination of human intuition and mechanical decision aids,"This study examines the intuitive combination of human judgment and mechanical prediction under varied information conditions, As expected, mechanical prediction outperformed human intuition when based on the same information, but a combined approach was best when judges had access to relevant information not captured by the model (information asymmetry), The model was useful for differentiating between the event outcomes (improved slope), while eliminating the bias caused by base-rate neglect. Human intuition was useful for incorporating relevant information outside the scope of the model, resulting in improved slope and reduced judgment scatter. The addition of irrelevant information was detrimental to judgment accuracy, causing an increase in bias and a reduction in slope. These results provide insight into hour and when combining mechanical prediction and human intuition is likely to result in improved accuracy. (C) 1998 Academic Press.",10.1006/obhd.1998.2809,1998,Y,N,Y,FALSE,
10,Automatic feature identification and graphical support in rule-based forecasting: A comparison,"We examined automatic feature identification and graphical support in rule-based expert systems for forecasting. The rule-based expert forecasting system (RBEFS) includes predefined rules to automatically identify features of a time series and selects the extrapolation method to be used. The system call also integrate managerial judgment using a graphical interface that allows a user to view alternate extrapolation methods two at a time. The use of the RBEFS led to a significant improvement in accuracy compared to equal-weight combinations of forecasts. Further improvement were achieved with the user interface. For 6-year ahead ex ante forecasts, the rule-based expert forecasting system has a median absolute percentage error (MdAPE) 15% less than that of equally weighted combined forecasts and a 33% improvement over the random walk. The user adjusted forecasts had a MdAPE 20% less than that of the expert system. The results of the system are also compared to those of an earlier rule-based expert system which required human judgments about some features of the time series data. The results of the comparison of the two rule-based expert systems showed no significant differences between them.",10.1016/S0169-2070(96)00682-6,1996,N,Y,N,FALSE,
14,Development of a surrogate model and sensitivity analysis for spatio-temporal numerical simulators,"To evaluate the consequences on human health of radionuclide releases in the environment, numerical simulators are used to model the radionuclide atmospheric dispersion. These codes can be time consuming and depend on many uncertain variables related to radionuclide, release or weather conditions. These variables are of different kind: scalar, functional and qualitative. Given the uncertain parameters, code provides spatial maps of radionuclide concentration for various moments. The objective is to assess how these uncertainties can affect the code predictions and to perform a global sensitivity analysis of code in order to identify the most influential uncertain parameters. This sensitivity analysis often calls for the estimation of variance-based importance measures, called Sobol' indices. To estimate these indices, we propose a global methodology combining several advanced statistical techniques which enable to deal with the various natures of the uncertain inputs and the high dimension of model outputs. First, a quantification of input uncertainties is made based on data analysis and expert judgment. Then, an initial realistic sampling design is generated and the corresponding code simulations are performed. Based on this sample, a proper orthogonal decomposition of the spatial output is used and the main decomposition coefficients are modeled with Gaussian process surrogate model. The obtained spatial metamodel is then used to compute spatial maps of Sobol' indices, yielding the identification of global and local influence of each input variable and the detection of areas with interactions. The impact of uncertainty quantification step on the results is also evaluated.",10.1007/s00477-014-0927-y,2015,N,N,N,FALSE,
17,Preliminary Strategic Environmental Assessment of the Great Western Development Strategy: Safeguarding Ecological Security for a New Western China,"The Great Western Development Strategy (GWDS) is a long term national campaign aimed at boosting development of the western area of China and narrowing the economic gap between the western and the eastern parts of China. The Strategic Environmental Assessment (SEA) procedure was employed to assess the environmental challenges brought about by the western development plans. These plans include five key developmental domains (KDDs): water resource exploitation and use, land utilization, energy generation, tourism development, and ecological restoration and conservation. A combination of methods involving matrix assessment, incorporation of expert judgment and trend analysis was employed to analyze and predict the environmental impacts upon eight selected environmental indicators: water resource availability, soil erosion, soil salinization, forest destruction, land desertification, biological diversity, water quality and air quality. Based on the overall results of the assessment, countermeasures for environmental challenges that emerged were raised as key recommendations to ensure ecological security during the implementation of the GWDS. This paper is intended to introduce a consensus-based process for evaluating the complex, long term pressures on the ecological security of large areas, such as western China, that focuses on the use of combined methods applied at the strategic level.",10.1007/s00267-011-9794-1,2012,Y,Y,Y,TRUE,
18,A human judgment approach to epidemiological forecasting,"Infectious diseases impose considerable burden on society, despite significant advances in technology and medicine over the past century. Advanced warning can be helpful in mitigating and preparing for an impending or ongoing epidemic. Historically, such a capability has lagged for many reasons, including in particular the uncertainty in the current state of the system and in the understanding of the processes that drive epidemic trajectories. Presently we have access to data, models, and computational resources that enable the development of epidemiological forecasting systems. Indeed, several recent challenges hosted by the U. S. government have fostered an open and collaborative environment for the development of these technologies. The primary focus of these challenges has been to develop statistical and computational methods for epidemiological forecasting, but here we consider a serious alternative based on collective human judgment. We created the web-based | Epicast forecasting system which collects and aggregates epidemic predictions made in real-time by human participants, and with these forecasts we ask two questions: how accurate is human judgment, and how do these forecasts compare to their more computational, data-driven alternatives? To address the former, we assess by a variety of metrics how accurately humans are able to predict influenza and chikungunya trajectories. As for the latter, we show that real-time, combined human predictions of the 2014-2015 and 2015-2016 U.S. flu seasons are often more accurate than the same predictions made by several statistical systems, especially for short-term targets. We conclude that there is valuable predictive power in collective human judgment, and we discuss the benefits and drawbacks of this approach.",10.1371/journal.pcbi.1005248,2017,Y,N,Y,FALSE,
21,AGGREGATION OF FORECASTS FROM MULTIPLE SIMULATION MODELS,"When faced with output from multiple simulation models, a decision maker must aggregate the forecasts provided by each model. This problem is made harder when the models are based on similar assumptions or use overlapping input data. This situation is similar to the problem of expert judgment aggregation where experts provide a forecast distribution based on overlapping information, but only samples from the output distribution are obtained in the simulation case. We propose a Bayesian method for aggregating forecasts from multiple simulation models. We demonstrate the approach using a climate change example, an area often informed by multiple simulation models.",0,2013,N,N,N,FALSE,
23,Comparing models for quantitative risk assessment: an application to the European Registry of foreign body injuries in children,"Risk Assessment is the systematic study of decisions subject to uncertain consequences. An increasing interest has been focused on modeling techniques like Bayesian Networks since their capability of (1) combining in the probabilistic framework different type of evidence including both expert judgments and objective data; (2) overturning previous beliefs in the light of the new information being received and (3) making predictions even with incomplete data. In this work, we proposed a comparison among Bayesian Networks and other classical Quantitative Risk Assessment techniques such as Neural Networks, Classification Trees, Random Forests and Logistic Regression models. Hybrid approaches, combining both Classification Trees and Bayesian Networks, were also considered. Among Bayesian Networks, a clear distinction between purely data-driven approach and combination of expert knowledge with objective data is made. The aim of this paper consists in evaluating among this models which best can be applied, in the framework of Quantitative Risk Assessment, to assess the safety of children who are exposed to the risk of inhalation/insertion/aspiration of consumer products. The issue of preventing injuries in children is of paramount importance, in particular where product design is involved: quantifying the risk associated to product characteristics can be of great usefulness in addressing the product safety design regulation. Data of the European Registry of Foreign Bodies Injuries formed the starting evidence for risk assessment. Results showed that Bayesian Networks appeared to have both the ease of interpretability and accuracy in making prediction, even if simpler models like logistic regression still performed well.",10.1177/0962280213476167,2016,N,Y,Y,FALSE,
24,Principles of forecasting - A short overview,"Forecasting procedures are needed when there is uncertainty about the future. In our contribution we discuss some principles that can help to make more accurate forecasts and help to better assess the uncertainty associated with forecasts. We mainly discuss statistical forecasting procedures, but other principles based on experts (judgmental forecasting) and integrating and combining approaches are also mentioned. We show some results of forecasting in two different application areas.",0,1999,N,Y,N,FALSE,
26,"Predicting elections: Experts, polls, and fundamentals","This study analyzes the relative accuracy of experts, polls, and the so-called 'fundamentals' in predicting the popular vote in the four U.S. presidential elections from 2004 to 2016. Although the majority (62%) of 452 expert forecasts correctly predicted the directional error of polls, the typical expert's vote share forecast was 7% (of the error) less accurate than a simple polling average from the same day. The results further suggest that experts follow the polls and do not sufficiently harness information incorporated in the fundamentals. Combining expert forecasts and polls with a fundamentals-based reference class forecast reduced the error of experts and polls by 24% and 19%, respectively. The findings demonstrate the benefits of combining forecasts and the effectiveness of taking the outside view for debiasing expert judgment.",0,2018,Y,Y,Y,TRUE,
29,A study on the space distribution and temporal evolvement of electric power load,"Spatial load forecasting hinges on choosing suitable load density. Because of load density is influenced by many uncertain factors, taking various objective factors into account on the basis of expert experience judgment will be a great help to improve the precision of forecasting load density. The selection of load density bases on a large number of samples. This paper establishes cloud generator to extend the data of finite samples. This paper selects the influence factors which play an important role in the load density and introduces cloud theory and analytic hierarchy process to analyze the combination weight vector of various factors. Use the ideal approximation method to select the optimal load density based on the expanded sample data and modify the load density based on the similarity method. Inputting the values of influencing factors in a given year of the area to be predicted, it can be worked out that the load density of the area in the given year. This method can not only predict the spatial distribution of the electric power load, but also predict the evolution process of the spatial load. An example demonstrates the superiority of the proposed model in spatial load forecasting.",0,2011,N,N,N,FALSE,
30,Optimization of bridge maintenance actions considering combination of sources of information: Inspections and expert judgment,"The use of advanced probabilistic life-cycle deterioration models is fundamental in bridge maintenance and management. However, such models must be based on direct and indirect information on structural performance, including results of inspections, health monitoring, but also expert judgment and information on other similar structures. A probabilistic deterioration model, considering both condition and safety as indicators of performance, is used as a decision aid in bridge management. The data considered for defining the performance profiles over time is based on the expert opinion, resulting from observation of similar structures. In order to reduce uncertainty and correct the existing predictions, the results of direct information, in the form of visuals inspections, are combined with the initial prediction. The combination of these two sources of information is performed considering Bayesian updating techniques. Based on this new information, it is possible, considering multi-objective optimization using genetic algorithms, to define the optimal lifetime maintenance strategy for a structure. The methodology is applied to a set of bridge components. The results show the significant improvement in prediction quality obtained by combining different sources of information, even if the quality of the obtained data is limited. Moreover, the impact of the new information on the optimal maintenance strategies is quantified.",0,2010,N,Y,Y,FALSE,
33,Multi-hierarchical durability assessment of existing reinforced-concrete structures,"Durability of an existing reinforced concrete structure is one of the most important problems for its users and owners. However, no systematic durability assessment approach exists currently. The assessment results vary in relation to the knowledge, expertise, and partiality of the assessor. Additionally, most assessment may not focus on all the key system parameters that affect structural durability. This paper aims at establishing a systematic durability assessment approach for R.C. Structures. The development of such an approach would help to identify all major parameters that affect structural durability and in addition, would enable assessors to collect both qualitative as well as quantitative information in a standard format for any given reinforced concrete structure. Furthermore, such a systematic assessment approach would provide a fair and objective way for analyzing and dealing with data collected by field inspection. Firstly, by Saaty's ratio scaling method, which scientifically quantifies the subjective information of expert judgments. Secondly, on basis of the properties of entropy, which combines the subjective information of expert judgments with the intrinsic information of assessment parameters. Then, taking gray relation grade as criterion, which obtains the deterioration degree and deterioration rate for a given structure. Finally, based on the assumption that deterioration varies with time exponentially, it gives the present performance and residual service life for any existing reinforced concrete structure.",0,1999,Y,Y,Y,TRUE,
1,Aggregating Probability Distributions,"This chapter is concerned with the aggregation of probability distributions in decision and risk analysis. Experts often provide valuable information regarding important uncertainties in decision and risk analyses because of the limited availability of hard data to use in those analyses. Multiple experts are often consulted in order to obtain as much information as possible, leading to the problem of how to combine or aggregate their information. Information may also be obtained from other sources such as forecasting techniques or scientific models. Because uncertainties are typically represented in terms of probability distributions, we consider expert and other information in terms of probability distributions. We discuss a variety of models that lead to specific combination methods. The output of these methods is a combined probability distribution, which can be viewed as representing a summary of the current state of information regarding the uncertainty of interest. After presenting the models and methods, we discuss empirical evidence on the performance of the methods. In the conclusion, we highlight important conceptual and practical issues to be considered when designing a combination process for use in practice.",10.1017/CBO9780511611308.010,2007,Y,Y,Y,TRUE,this one looks highly relevant!
6,Median Aggregation of Distribution Functions,"When multiple redundant probabilistic judgments are obtained from subject matter experts, it is common practice to aggregate their differing views into a single probability or distribution. Although many methods have been proposed for mathematical aggregation, no single procedure has gained universal acceptance. The most widely used procedure is simple arithmetic averaging, which has both desirable and undesirable properties. Here we propose an alternative for aggregating distribution functions that is based on the median cumulative probabilities at fixed values of the variable. It is shown that aggregating cumulative probabilities by medians is equivalent, under certain conditions, to aggregating quantiles. Moreover, the median aggregate has better calibration than mean aggregation of probabilities when the experts are independent and well calibrated and produces sharper aggregate distributions for well-calibrated and independent experts when they report a common location-scale distribution. We also compare median aggregation to mean aggregation of quantiles.",10.1287/deca.2013.0282,2013,Y,Y,Y,TRUE,highly relevant!
9,Crowd Wisdom Relies on Agents' Ability in Small Groups with a Voting Aggregation Rule,"In the last decade, interest in the ""wisdom of crowds"" effect has gained momentum in both organizational research and corporate practice. Crowd wisdom relies on the aggregation of independent judgments. The accuracy of a group's aggregate prediction rises with the number, ability, and diversity of its members. We investigate these variables' relative importance for collective prediction using agent-based simulation. We replicate the ""diversity trumps ability"" proposition for large groups, showing that samples of heterogeneous agents outperform same-sized homogeneous teams of high ability. In groups smaller than approximately 16 members, however, the effects of group composition depend on the social decision function employed: diversity is key only in continuous estimation tasks (averaging) and much less important in discrete choice tasks (voting), in which agents' individual abilities remain crucial. Thus, strategies to improve collective decision making must adapt to the predictive situation at hand.",10.1287/mnsc.2015.2364,2017,Y,N,Y,FALSE,
11,Combination and Selection of Traffic Safety Expert Judgments for the Prevention of Driving Risks,"In this paper, we describe a new framework to combine experts' judgments for the prevention of driving risks in a cabin truck. In addition, the methodology shows how to choose among the experts the one whose predictions fit best the environmental conditions. The methodology is applied over data sets obtained from a high immersive cabin truck simulator in natural driving conditions. A nonparametric model, based in Nearest Neighbors combined with Restricted Least Squared methods is developed. Three experts were asked to evaluate the driving risk using a Visual Analog Scale (VAS), in order to measure the driving risk in a truck simulator where the vehicle dynamics factors were stored. Numerical results show that the methodology is suitable for embedding in real time systems.",10.3390/s121114711,2012,Y,Y,Y,TRUE,
12,A Demand Forecasting Methodology for Fuzzy Environments,"Several supply chain and production planning models in the literature assume the demands are fuzzy but most of them do not offer a specific technique to derive the fuzzy demands. In this study, we propose a methodology to obtain a fuzzy-demand forecast that is represented by a possibilistic distribution. The fuzzy-demand forecast is found by aggregating forecasts based on different sources; namely statistical forecasting methods and experts' judgments. In the methodology, initially, the forecast derived from the statistical forecasting techniques and experts' judgments are represented by triangular possibilistic distributions. Subsequently, those results are combined by using weights assigned to each of them. A new objective weighting approach is used to find the weights. The proposed methodology is illustrated by an example and a sensitivity analysis is provided.",0,2010,Y,Y,Y,TRUE,
13,Recommending Outfits from Personal Closet,"We consider grading a fashion outfit for recommendation, where we assume that users have a closet of items and we aim at producing a score for an arbitrary combination of items in the closet. The challenge in outfit grading is that the input to the system is a bag of item pictures that are unordered and vary in size. We build a deep neural network-based system that can take variable-length items and predict a score. We collect a large number of outfits from a popular fashion sharing website, Polyvore, and evaluate the performance of our grading system. We compare our model with a random-choice baseline, both on the traditional classification evaluation and on people's judgment using a crowdsourcing platform. With over 84% in classification accuracy and 91% matching ratio to human annotators, our model can reliably grade the quality of an outfit. We also build an outfit recommender on top of our grader to demonstrate the practical application of our model for a personal closet assistant.",10.1109/WACV.2018.00036,2018,Y,N,Y,FALSE,
14,Deriving the probability of a linear opinion pooling method being superior to a set of alternatives,"Linear opinion pools are a common method for combining a set of distinct opinions into a single succinct opinion, often to be used in a decision making task. In this paper we consider a method, termed the Plug-in approach, for determining the weights to be assigned in this linear pool, in a manner that can be deemed as rational in some sense, while incorporating multiple forms of learning over time into its process. The environment that we consider is one in which every source in the pool is herself a decision maker (DM), in contrast to the more common setting in which expert judgments are amalgamated for use by a single DM. We discuss a simulation study that was conducted to show the merits of our technique, and demonstrate how theoretical probabilistic arguments can be used to exactly quantify the probability of this technique being superior (in terms of a probability density metric) to a set of alternatives. Illustrations are given of simulated proportions converging to these true probabilities in a range of commonly used distributional cases.",10.1016/j.ress.2016.10.008,2017,Y,Y,Y,TRUE,
15,Uncertainty and Expert Assessment for Supporting Evaluation of Levees Safety,"In France, levees remain most of the time badly maintained; these long linear structures show signs of weaknesses on numerous occasions. Only incomplete information is usually available. The general lack of data describing the behavior of the infrastructure during unwanted events led to estimate their safety mainly from expert judgment. Thus the ability of the expert to predict the level of functioning of an infrastructure for a type of hazard and its intensity is crucial. An error of judgment can have very serious consequences and the production of reliable information requires the ability of the expert to report accurately the uncertainties in its estimations, as well as associated confidence. In order to meet this need, our research within Incertu project (French Ministry of Ecology funding) aims to produce relevant scientific approaches and tools for the collection and processing reliable experts' statements or combined with a confidence level in the context of uncertain information and input data.",10.1051/e3sconf/20160703019,2016,Y,Y,Y,TRUE,